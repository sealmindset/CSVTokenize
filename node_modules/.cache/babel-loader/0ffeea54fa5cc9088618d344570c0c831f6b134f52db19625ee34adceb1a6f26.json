{"ast":null,"code":"var _jsxFileName = \"/Users/robvance/Documents/GitHub/csvclean/src/FileParser.js\",\n  _s = $RefreshSig$();\nimport React, { useState } from 'react';\nimport Papa from 'papaparse';\nimport DataTableDisplay from './DataTableDisplay';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst FileParser = () => {\n  _s();\n  const [parsedData, setParsedData] = useState(null);\n  const handleFileUpload = file => {\n    Papa.parse(file, {\n      complete: handleParsingComplete,\n      header: true,\n      skipEmptyLines: true\n    });\n  };\n  const handleParsingComplete = results => {\n    const {\n      data,\n      meta\n    } = results;\n    const columnHeaders = Object.keys(data[0]);\n    const tokenizedData = tokenizeData(data, columnHeaders);\n    setParsedData({\n      columnHeaders,\n      data: tokenizedData\n    });\n  };\n  const tokenizeData = (data, columnHeaders) => {\n    // Helper function to generate tokenized versions of unique data\n    const generateToken = data => {\n      // Logic to transform data into tokens goes here\n      // For simplicity, let's use the input data prefixed with \"token_\" for illustration purposes\n      return `token_${data}`;\n    };\n\n    // Create a map to store tokenized versions of unique data for each column\n    const tokenMap = {};\n\n    // Loop through each column and tokenize the unique data\n    columnHeaders.forEach(header => {\n      const uniqueData = new Set(data.map(row => row[header]));\n\n      // Convert the set of unique data into an array of tokenized data\n      const tokenizedData = Array.from(uniqueData).map(data => ({\n        original: data,\n        tokenized: generateToken(data)\n      }));\n\n      // Store the tokenized data in the map\n      tokenMap[header] = tokenizedData;\n    });\n\n    // Loop through each row and replace the original data with tokenized data\n    const tokenizedData = data.map(row => {\n      const newRow = {};\n      columnHeaders.forEach(header => {\n        const originalData = row[header];\n        const tokenizedData = tokenMap[header].find(item => item.original === originalData);\n        newRow[header] = tokenizedData ? tokenizedData.tokenized : originalData;\n      });\n      return newRow;\n    });\n    return tokenizedData;\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"input\", {\n      type: \"file\",\n      accept: \".csv\",\n      onChange: e => handleFileUpload(e.target.files[0])\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 67,\n      columnNumber: 7\n    }, this), parsedData && /*#__PURE__*/_jsxDEV(DataTableDisplay, {\n      data: parsedData.data,\n      columns: parsedData.columnHeaders\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 68,\n      columnNumber: 22\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 66,\n    columnNumber: 5\n  }, this);\n};\n_s(FileParser, \"SziSJrYNR/GTQsYkzh2yf6yyoy4=\");\n_c = FileParser;\nexport default FileParser;\nvar _c;\n$RefreshReg$(_c, \"FileParser\");","map":{"version":3,"names":["React","useState","Papa","DataTableDisplay","jsxDEV","_jsxDEV","FileParser","_s","parsedData","setParsedData","handleFileUpload","file","parse","complete","handleParsingComplete","header","skipEmptyLines","results","data","meta","columnHeaders","Object","keys","tokenizedData","tokenizeData","generateToken","tokenMap","forEach","uniqueData","Set","map","row","Array","from","original","tokenized","newRow","originalData","find","item","children","type","accept","onChange","e","target","files","fileName","_jsxFileName","lineNumber","columnNumber","columns","_c","$RefreshReg$"],"sources":["/Users/robvance/Documents/GitHub/csvclean/src/FileParser.js"],"sourcesContent":["import React, { useState } from 'react';\nimport Papa from 'papaparse';\nimport DataTableDisplay from './DataTableDisplay';\n\nconst FileParser = () => {\n  const [parsedData, setParsedData] = useState(null);\n\n  const handleFileUpload = (file) => {\n    Papa.parse(file, {\n      complete: handleParsingComplete,\n      header: true,\n      skipEmptyLines: true,\n    });\n  };\n\n  const handleParsingComplete = (results) => {\n    const { data, meta } = results;\n    const columnHeaders = Object.keys(data[0]);\n    const tokenizedData = tokenizeData(data, columnHeaders);\n    setParsedData({ columnHeaders, data: tokenizedData });\n  };\n\n  const tokenizeData = (data, columnHeaders) => {\n    // Helper function to generate tokenized versions of unique data\n    const generateToken = (data) => {\n      // Logic to transform data into tokens goes here\n      // For simplicity, let's use the input data prefixed with \"token_\" for illustration purposes\n      return `token_${data}`;\n    };\n\n    // Create a map to store tokenized versions of unique data for each column\n    const tokenMap = {};\n\n    // Loop through each column and tokenize the unique data\n    columnHeaders.forEach((header) => {\n      const uniqueData = new Set(data.map((row) => row[header]));\n\n      // Convert the set of unique data into an array of tokenized data\n      const tokenizedData = Array.from(uniqueData).map((data) => ({\n        original: data,\n        tokenized: generateToken(data),\n      }));\n\n      // Store the tokenized data in the map\n      tokenMap[header] = tokenizedData;\n    });\n\n    // Loop through each row and replace the original data with tokenized data\n    const tokenizedData = data.map((row) => {\n      const newRow = {};\n\n      columnHeaders.forEach((header) => {\n        const originalData = row[header];\n        const tokenizedData = tokenMap[header].find((item) => item.original === originalData);\n\n        newRow[header] = tokenizedData ? tokenizedData.tokenized : originalData;\n      });\n\n      return newRow;\n    });\n\n    return tokenizedData;\n  };\n\n  return (\n    <div>\n      <input type=\"file\" accept=\".csv\" onChange={(e) => handleFileUpload(e.target.files[0])} />\n      {parsedData && <DataTableDisplay data={parsedData.data} columns={parsedData.columnHeaders} />}\n    </div>\n  );\n};\n\nexport default FileParser;\n\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,QAAQ,OAAO;AACvC,OAAOC,IAAI,MAAM,WAAW;AAC5B,OAAOC,gBAAgB,MAAM,oBAAoB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAElD,MAAMC,UAAU,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACvB,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGR,QAAQ,CAAC,IAAI,CAAC;EAElD,MAAMS,gBAAgB,GAAIC,IAAI,IAAK;IACjCT,IAAI,CAACU,KAAK,CAACD,IAAI,EAAE;MACfE,QAAQ,EAAEC,qBAAqB;MAC/BC,MAAM,EAAE,IAAI;MACZC,cAAc,EAAE;IAClB,CAAC,CAAC;EACJ,CAAC;EAED,MAAMF,qBAAqB,GAAIG,OAAO,IAAK;IACzC,MAAM;MAAEC,IAAI;MAAEC;IAAK,CAAC,GAAGF,OAAO;IAC9B,MAAMG,aAAa,GAAGC,MAAM,CAACC,IAAI,CAACJ,IAAI,CAAC,CAAC,CAAC,CAAC;IAC1C,MAAMK,aAAa,GAAGC,YAAY,CAACN,IAAI,EAAEE,aAAa,CAAC;IACvDX,aAAa,CAAC;MAAEW,aAAa;MAAEF,IAAI,EAAEK;IAAc,CAAC,CAAC;EACvD,CAAC;EAED,MAAMC,YAAY,GAAGA,CAACN,IAAI,EAAEE,aAAa,KAAK;IAC5C;IACA,MAAMK,aAAa,GAAIP,IAAI,IAAK;MAC9B;MACA;MACA,OAAQ,SAAQA,IAAK,EAAC;IACxB,CAAC;;IAED;IACA,MAAMQ,QAAQ,GAAG,CAAC,CAAC;;IAEnB;IACAN,aAAa,CAACO,OAAO,CAAEZ,MAAM,IAAK;MAChC,MAAMa,UAAU,GAAG,IAAIC,GAAG,CAACX,IAAI,CAACY,GAAG,CAAEC,GAAG,IAAKA,GAAG,CAAChB,MAAM,CAAC,CAAC,CAAC;;MAE1D;MACA,MAAMQ,aAAa,GAAGS,KAAK,CAACC,IAAI,CAACL,UAAU,CAAC,CAACE,GAAG,CAAEZ,IAAI,KAAM;QAC1DgB,QAAQ,EAAEhB,IAAI;QACdiB,SAAS,EAAEV,aAAa,CAACP,IAAI;MAC/B,CAAC,CAAC,CAAC;;MAEH;MACAQ,QAAQ,CAACX,MAAM,CAAC,GAAGQ,aAAa;IAClC,CAAC,CAAC;;IAEF;IACA,MAAMA,aAAa,GAAGL,IAAI,CAACY,GAAG,CAAEC,GAAG,IAAK;MACtC,MAAMK,MAAM,GAAG,CAAC,CAAC;MAEjBhB,aAAa,CAACO,OAAO,CAAEZ,MAAM,IAAK;QAChC,MAAMsB,YAAY,GAAGN,GAAG,CAAChB,MAAM,CAAC;QAChC,MAAMQ,aAAa,GAAGG,QAAQ,CAACX,MAAM,CAAC,CAACuB,IAAI,CAAEC,IAAI,IAAKA,IAAI,CAACL,QAAQ,KAAKG,YAAY,CAAC;QAErFD,MAAM,CAACrB,MAAM,CAAC,GAAGQ,aAAa,GAAGA,aAAa,CAACY,SAAS,GAAGE,YAAY;MACzE,CAAC,CAAC;MAEF,OAAOD,MAAM;IACf,CAAC,CAAC;IAEF,OAAOb,aAAa;EACtB,CAAC;EAED,oBACElB,OAAA;IAAAmC,QAAA,gBACEnC,OAAA;MAAOoC,IAAI,EAAC,MAAM;MAACC,MAAM,EAAC,MAAM;MAACC,QAAQ,EAAGC,CAAC,IAAKlC,gBAAgB,CAACkC,CAAC,CAACC,MAAM,CAACC,KAAK,CAAC,CAAC,CAAC;IAAE;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,EACxF1C,UAAU,iBAAIH,OAAA,CAACF,gBAAgB;MAACe,IAAI,EAAEV,UAAU,CAACU,IAAK;MAACiC,OAAO,EAAE3C,UAAU,CAACY;IAAc;MAAA2B,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAC1F,CAAC;AAEV,CAAC;AAAC3C,EAAA,CAlEID,UAAU;AAAA8C,EAAA,GAAV9C,UAAU;AAoEhB,eAAeA,UAAU;AAAC,IAAA8C,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}